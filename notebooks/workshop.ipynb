{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iceberg Workshop: Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_catalog\n",
    "\n",
    "catalog = load_catalog(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Data\n",
    "\n",
    "| name    | id | date       |\n",
    "|---------|----|------------|\n",
    "| Alice   |  1 | 2018-04-02 |\n",
    "| Bob     |  2 | 2020-09-07 |\n",
    "| Charlie |  3 | 2022-07-01 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "\n",
    "example_schema = pa.schema(\n",
    "    [\n",
    "        (\"name\", pa.string()),\n",
    "        (\"id\", pa.int32()),\n",
    "        (\"date\", pa.date32()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_data = pa.Table.from_pylist([\n",
    "    {\"name\": \"Alice\", \"id\": 1, \"date\": 17623},  # 2018-05-15\n",
    "    {\"name\": \"Bob\", \"id\": 2, \"date\": 18512},    # 2020-11-23\n",
    "    {\"name\": \"Charlie\", \"id\": 3, \"date\": 19174} # 2022-07-07\n",
    "], schema=example_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Iceberg table\n",
    "\n",
    "First, we'll create a namespace `demo_ns` to organize the Iceberg table, then define and create the table using the specified schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.create_namespace_if_not_exists(\"demo_ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_table_1(\n",
       "  1: name: optional string,\n",
       "  2: id: optional int,\n",
       "  3: date: optional date\n",
       "),\n",
       "partition by: [],\n",
       "sort order: [],\n",
       "snapshot: null"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = catalog.create_table(\"demo_ns.demo_table_1\", schema=example_schema)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## What happens behind table creation?\n",
    "\n",
    "A metadata file has been created and registered as the latest metadata of table `demo_ns.demo_table_1`. Let's login to Minio Bucket and see the file:\n",
    "\n",
    "- Minio Url: http://localhost:9001/\n",
    "- username: admin\n",
    "- password: password\n",
    "\n",
    "The table is created at [s3://warehouse/demo_ns/demo_table_1](http://localhost:9001/browser/warehouse/demo_ns%2Fdemo_table_1%2F): \n",
    "\n",
    "![](./imgs/simple_table_create.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data to the table\n",
    "\n",
    "It will create a new snapshot on the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pyiceberg/table/__init__.py:686: UserWarning: Delete operation did not match any records\n",
      "  warnings.warn(\"Delete operation did not match any records\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "demo_table_1(\n",
       "  1: name: optional string,\n",
       "  2: id: optional int,\n",
       "  3: date: optional date\n",
       "),\n",
       "partition by: [],\n",
       "sort order: [],\n",
       "snapshot: Operation.APPEND: id=1254590870239251066, schema_id=0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.overwrite(example_data)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the table\n",
    "\n",
    "We can see example data has been added to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  id        date\n",
       "0    Alice   1  2018-04-02\n",
       "1      Bob   2  2020-09-07\n",
       "2  Charlie   3  2022-07-01"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.scan().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happens when adding data?\n",
    "\n",
    "The data has been written into a parquet file and a new snapshot has been created.\n",
    "\n",
    "Let's check the table location again: [s3://warehouse/demo_ns/demo_table_1](http://localhost:9001/browser/warehouse/demo_ns%2Fdemo_table_1%2F)\n",
    "\n",
    "We can see the table now have both `metadata` and `data`\n",
    "![](./imgs/simple_table_create_append_data.png)\n",
    "\n",
    "In the `metadata`, we can see some new files are generated\n",
    "![](./imgs/simple_table_create_append_data_new_metadata.png)\n",
    "\n",
    "In the `data`, we can see a new parquet file that contains the inserted data\n",
    "![](./imgs/simple_table_create_append_data_new_data.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Evolution: Make table partitioned\n",
    "\n",
    "The table we just created is unpartitioned, but it's common practice to partition a table based on specific column(s). No worries—we can easily partition it!\n",
    "\n",
    "Iceberg allows you to update the partitioning strategy without having to recreate the table or migrate any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_table_1(\n",
       "  1: name: optional string,\n",
       "  2: id: optional int,\n",
       "  3: date: optional date\n",
       "),\n",
       "partition by: [date_year],\n",
       "sort order: [],\n",
       "snapshot: Operation.APPEND: id=7948635370284362920, schema_id=0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiceberg.transforms import YearTransform\n",
    "\n",
    "with table.update_spec() as update:\n",
    "   update.add_field(\"date\", YearTransform())\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add more data to partitioned table\n",
    "\n",
    "New data will be written in to different partitions based on the partition strategy. In this demo, there will be 3 partitions\n",
    "\n",
    "- date_year=2018\n",
    "- date_year=2020\n",
    "- date_year=2022\n",
    "\n",
    "TODO: Add a preview of current file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data_2 = pa.Table.from_pylist([\n",
    "    {\"name\": \"David\", \"id\": 4, \"date\": 17623},  # 2018-05-15\n",
    "    {\"name\": \"John\", \"id\": 5, \"date\": 18512},    # 2020-11-23\n",
    "    {\"name\": \"Jonas\", \"id\": 6, \"date\": 19174} # 2022-07-07\n",
    "], schema=example_schema)\n",
    "\n",
    "table.append(example_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jonas</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  id        date\n",
       "0    David   4  2018-04-02\n",
       "1     John   5  2020-09-07\n",
       "2    Jonas   6  2022-07-01\n",
       "3    Alice   1  2018-04-02\n",
       "4      Bob   2  2020-09-07\n",
       "5  Charlie   3  2022-07-01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.scan().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Evolution: Add new column to the table\n",
    "\n",
    "Iceberg allows user to add new column(s) without re-create or re-write the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.types import StringType, DecimalType\n",
    "\n",
    "with table.update_schema() as update:\n",
    "   # Add new columns\n",
    "   update.add_column(\"comments\", StringType())\n",
    "   update.add_column(\"salary\", DecimalType(9, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "demo_table_1(\n",
       "  1: name: optional string,\n",
       "  2: id: optional int,\n",
       "  3: date: optional date,\n",
       "  4: comments: optional string,\n",
       "  5: salary: optional decimal(9, 3)\n",
       "),\n",
       "partition by: [date_year],\n",
       "sort order: [],\n",
       "snapshot: Operation.APPEND: id=6696808655765377924, parent_id=4688774704661413985, schema_id=0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>comments</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jonas</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-02</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  id        date comments salary\n",
       "0    David   4  2018-04-02     None   None\n",
       "1     John   5  2020-09-07     None   None\n",
       "2    Jonas   6  2022-07-01     None   None\n",
       "3    Alice   1  2018-04-02     None   None\n",
       "4      Bob   2  2020-09-07     None   None\n",
       "5  Charlie   3  2022-07-01     None   None"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.scan().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Dataset\n",
    "Now let's use New York City Taxi & Limousine Commission's Trip Record Data to show more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID: int32\n",
       "tpep_pickup_datetime: timestamp[us]\n",
       "tpep_dropoff_datetime: timestamp[us]\n",
       "passenger_count: int64\n",
       "trip_distance: double\n",
       "RatecodeID: int64\n",
       "store_and_fwd_flag: large_string\n",
       "PULocationID: int32\n",
       "DOLocationID: int32\n",
       "payment_type: int64\n",
       "fare_amount: double\n",
       "extra: double\n",
       "mta_tax: double\n",
       "tip_amount: double\n",
       "tolls_amount: double\n",
       "improvement_surcharge: double\n",
       "total_amount: double\n",
       "congestion_surcharge: double\n",
       "Airport_fee: double"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "taxis_data_jan = pq.read_table('/home/jovyan/data/yellow_tripdata_2024-01.parquet')\n",
    "taxis_data_feb = pq.read_table('/home/jovyan/data/yellow_tripdata_2024-02.parquet')\n",
    "taxis_data_march = pq.read_table('/home/jovyan/data/yellow_tripdata_2024-03.parquet')\n",
    "taxis_data_jan.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an Iceberg Table with that Schema\n",
    "\n",
    "Let's say we want to partition by the pickup time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_taxis_tbl = catalog.create_table(\"demo_ns.nyc_taxis\", schema=taxis_data_jan.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Evolution: Make table partitioned\n",
    "\n",
    "The table we just created is unpartitioned. In this example, we want to take a further step to partition the table. We will partition the table by the `year` value of`tpep_pickup_datatime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nyc_taxis(\n",
       "  1: VendorID: optional int,\n",
       "  2: tpep_pickup_datetime: optional timestamp,\n",
       "  3: tpep_dropoff_datetime: optional timestamp,\n",
       "  4: passenger_count: optional long,\n",
       "  5: trip_distance: optional double,\n",
       "  6: RatecodeID: optional long,\n",
       "  7: store_and_fwd_flag: optional string,\n",
       "  8: PULocationID: optional int,\n",
       "  9: DOLocationID: optional int,\n",
       "  10: payment_type: optional long,\n",
       "  11: fare_amount: optional double,\n",
       "  12: extra: optional double,\n",
       "  13: mta_tax: optional double,\n",
       "  14: tip_amount: optional double,\n",
       "  15: tolls_amount: optional double,\n",
       "  16: improvement_surcharge: optional double,\n",
       "  17: total_amount: optional double,\n",
       "  18: congestion_surcharge: optional double,\n",
       "  19: Airport_fee: optional double\n",
       "),\n",
       "partition by: [tpep_pickup_datetime_year],\n",
       "sort order: [],\n",
       "snapshot: null"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyiceberg.transforms import YearTransform\n",
    "\n",
    "with nyc_taxis_tbl.update_spec() as update_spec:\n",
    "    update_spec.add_field(\"tpep_pickup_datetime\", YearTransform())\n",
    "\n",
    "nyc_taxis_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_taxis_tbl.append(taxis_data_jan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113470850"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_taxis_tbl.scan().to_pandas().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioned Data\n",
    "\n",
    "If we go to the [`data` folder](http://localhost:9001/browser/warehouse/demo_ns%2Fnyc_taxis%2Fdata%2F) of table `nyc_taxis`:\n",
    "\n",
    "![](./imgs/nyc_year_partition.png)\n",
    "\n",
    "We can see that inserted data partitioned by year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Evolution: Change to partition by month\n",
    "\n",
    "I changed my mind and now I want to partition the table by the \"month\" of `tpep_pickup_datetime`. No worries—we can easily partition it!\n",
    "\n",
    "Iceberg allows you to update the partitioning strategy without recreating the table or re-writing any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.transforms import MonthTransform\n",
    "\n",
    "with nyc_taxis_tbl.update_spec() as update_spec:\n",
    "    update_spec.remove_field(\"tpep_pickup_datetime_year\")\n",
    "    update_spec.add_field(\"tpep_pickup_datetime\", MonthTransform())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's append another month of data to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_taxis_tbl.append(taxis_data_feb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go to the the [`data` folder](http://localhost:9001/browser/warehouse/demo_ns%2Fnyc_taxis%2Fdata%2F) of table `nyc_taxis` again, we will find the new data is partitioned by the month value\n",
    "\n",
    "![](./imgs/nyc_month_partition.png)\n",
    "\n",
    "The previous year partitions' folders are still there because data inserted before partition spec change will remain in their original partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: PartitionSpec(spec_id=0),\n",
       " 1: PartitionSpec(PartitionField(source_id=2, field_id=1000, transform=YearTransform(), name='tpep_pickup_datetime_year'), spec_id=1),\n",
       " 2: PartitionSpec(PartitionField(source_id=2, field_id=1001, transform=MonthTransform(), name='tpep_pickup_datetime_month'), spec_id=2)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_taxis_tbl.specs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Evolution: Change Table Schema\n",
    "Iceberg supports schema evolution without rewriting any data. For example, we can rename `VendorId` to `ID`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-01 23:58:40</td>\n",
       "      <td>2009-01-02 00:01:40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>137</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-01 23:30:39</td>\n",
       "      <td>2009-01-02 00:01:39</td>\n",
       "      <td>1</td>\n",
       "      <td>10.99</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>237</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-01 00:24:09</td>\n",
       "      <td>2009-01-01 01:13:00</td>\n",
       "      <td>2</td>\n",
       "      <td>10.88</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>50.6</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2009-01-01 23:58:40   2009-01-02 00:01:40                1   \n",
       "1         2  2009-01-01 23:30:39   2009-01-02 00:01:39                1   \n",
       "2         2  2009-01-01 00:24:09   2009-01-01 01:13:00                2   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.46           1                  N           137           264   \n",
       "1          10.99           1                  N           237           264   \n",
       "2          10.88           1                  N           138           264   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          4.4   3.50      0.5         0.0          0.00   \n",
       "1             2         45.0   3.50      0.5         0.0          0.00   \n",
       "2             2         50.6   9.25      0.5         0.0          6.94   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0          9.40                   0.0          0.0  \n",
       "1                    1.0         50.00                   0.0          0.0  \n",
       "2                    1.0         68.29                   0.0          0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before rename\n",
    "nyc_taxis_tbl.scan(limit=3).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nyc_taxis_tbl.update_schema() as update:\n",
    "    update.rename_column(\"VendorID\", \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-31 23:59:53</td>\n",
       "      <td>2024-02-01 00:18:35</td>\n",
       "      <td>1</td>\n",
       "      <td>6.95</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>249</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-31 23:59:24</td>\n",
       "      <td>2024-02-01 00:06:13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-31 23:57:33</td>\n",
       "      <td>2024-02-01 00:05:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0   2  2024-01-31 23:59:53   2024-02-01 00:18:35                1   \n",
       "1   2  2024-01-31 23:59:24   2024-02-01 00:06:13                1   \n",
       "2   2  2024-01-31 23:57:33   2024-02-01 00:05:48                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           6.95           1                  N           249           166   \n",
       "1           1.28           1                  N            68           137   \n",
       "2           1.40           1                  N            90            79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         30.3    1.0      0.5        7.06           0.0   \n",
       "1             2          9.3    1.0      0.5        0.00           0.0   \n",
       "2             1         10.0    1.0      0.5        1.95           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         42.36                   2.5          0.0  \n",
       "1                    1.0         14.30                   2.5          0.0  \n",
       "2                    1.0         16.95                   2.5          0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After rename\n",
    "nyc_taxis_tbl.scan(limit=3).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Table\n",
    "\n",
    "We can get more details of an iceberg by looking at its metadata tables. \n",
    "\n",
    "## Partitions\n",
    "For example, to learn about existing partitions in the table, we can query the `partitions` metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>record_count</th>\n",
       "      <th>file_count</th>\n",
       "      <th>total_data_file_size_in_bytes</th>\n",
       "      <th>position_delete_record_count</th>\n",
       "      <th>position_delete_file_count</th>\n",
       "      <th>equality_delete_record_count</th>\n",
       "      <th>equality_delete_file_count</th>\n",
       "      <th>last_updated_at</th>\n",
       "      <th>last_updated_snapshot_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tpep_pickup_datetime_year': None, 'tpep_pick...</td>\n",
       "      <td>2</td>\n",
       "      <td>3007511</td>\n",
       "      <td>1</td>\n",
       "      <td>52102669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:22:37.199</td>\n",
       "      <td>5248436113935406231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tpep_pickup_datetime_year': None, 'tpep_pick...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8041</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:22:37.199</td>\n",
       "      <td>5248436113935406231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tpep_pickup_datetime_year': None, 'tpep_pick...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:22:37.199</td>\n",
       "      <td>5248436113935406231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tpep_pickup_datetime_year': None, 'tpep_pick...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:22:37.199</td>\n",
       "      <td>5248436113935406231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tpep_pickup_datetime_year': None, 'tpep_pick...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7565</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:22:37.199</td>\n",
       "      <td>5248436113935406231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'tpep_pickup_datetime_year': 54.0, 'tpep_pick...</td>\n",
       "      <td>1</td>\n",
       "      <td>2964609</td>\n",
       "      <td>1</td>\n",
       "      <td>51732500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:13:26.142</td>\n",
       "      <td>6445851743841051392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'tpep_pickup_datetime_year': 53.0, 'tpep_pick...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:13:26.142</td>\n",
       "      <td>6445851743841051392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'tpep_pickup_datetime_year': 39.0, 'tpep_pick...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:13:26.142</td>\n",
       "      <td>6445851743841051392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'tpep_pickup_datetime_year': 32.0, 'tpep_pick...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-03 02:13:26.142</td>\n",
       "      <td>6445851743841051392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           partition  spec_id  record_count  \\\n",
       "0  {'tpep_pickup_datetime_year': None, 'tpep_pick...        2       3007511   \n",
       "1  {'tpep_pickup_datetime_year': None, 'tpep_pick...        2            11   \n",
       "2  {'tpep_pickup_datetime_year': None, 'tpep_pick...        2             1   \n",
       "3  {'tpep_pickup_datetime_year': None, 'tpep_pick...        2             1   \n",
       "4  {'tpep_pickup_datetime_year': None, 'tpep_pick...        2             2   \n",
       "5  {'tpep_pickup_datetime_year': 54.0, 'tpep_pick...        1       2964609   \n",
       "6  {'tpep_pickup_datetime_year': 53.0, 'tpep_pick...        1            10   \n",
       "7  {'tpep_pickup_datetime_year': 39.0, 'tpep_pick...        1             3   \n",
       "8  {'tpep_pickup_datetime_year': 32.0, 'tpep_pick...        1             2   \n",
       "\n",
       "   file_count  total_data_file_size_in_bytes  position_delete_record_count  \\\n",
       "0           1                       52102669                             0   \n",
       "1           1                           8041                             0   \n",
       "2           1                           7501                             0   \n",
       "3           1                           7501                             0   \n",
       "4           1                           7565                             0   \n",
       "5           1                       51732500                             0   \n",
       "6           1                           8028                             0   \n",
       "7           1                           7619                             0   \n",
       "8           1                           7541                             0   \n",
       "\n",
       "   position_delete_file_count  equality_delete_record_count  \\\n",
       "0                           0                             0   \n",
       "1                           0                             0   \n",
       "2                           0                             0   \n",
       "3                           0                             0   \n",
       "4                           0                             0   \n",
       "5                           0                             0   \n",
       "6                           0                             0   \n",
       "7                           0                             0   \n",
       "8                           0                             0   \n",
       "\n",
       "   equality_delete_file_count         last_updated_at  \\\n",
       "0                           0 2025-04-03 02:22:37.199   \n",
       "1                           0 2025-04-03 02:22:37.199   \n",
       "2                           0 2025-04-03 02:22:37.199   \n",
       "3                           0 2025-04-03 02:22:37.199   \n",
       "4                           0 2025-04-03 02:22:37.199   \n",
       "5                           0 2025-04-03 02:13:26.142   \n",
       "6                           0 2025-04-03 02:13:26.142   \n",
       "7                           0 2025-04-03 02:13:26.142   \n",
       "8                           0 2025-04-03 02:13:26.142   \n",
       "\n",
       "   last_updated_snapshot_id  \n",
       "0       5248436113935406231  \n",
       "1       5248436113935406231  \n",
       "2       5248436113935406231  \n",
       "3       5248436113935406231  \n",
       "4       5248436113935406231  \n",
       "5       6445851743841051392  \n",
       "6       6445851743841051392  \n",
       "7       6445851743841051392  \n",
       "8       6445851743841051392  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_taxis_tbl.inspect.partitions().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files\n",
    "\n",
    "If we want to see all the data files in the table, we can query the `files` metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>file_path</th>\n",
       "      <th>file_format</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>record_count</th>\n",
       "      <th>file_size_in_bytes</th>\n",
       "      <th>column_sizes</th>\n",
       "      <th>value_counts</th>\n",
       "      <th>null_value_counts</th>\n",
       "      <th>nan_value_counts</th>\n",
       "      <th>lower_bounds</th>\n",
       "      <th>upper_bounds</th>\n",
       "      <th>key_metadata</th>\n",
       "      <th>split_offsets</th>\n",
       "      <th>equality_ids</th>\n",
       "      <th>sort_order_id</th>\n",
       "      <th>readable_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>2</td>\n",
       "      <td>3007511</td>\n",
       "      <td>52102669</td>\n",
       "      <td>[(1, 351886), (2, 13833395), (3, 14013827), (4...</td>\n",
       "      <td>[(1, 3007511), (2, 3007511), (3, 3007511), (4,...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 185610), (5, 0), ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x01\\x00\\x00\\x00'), (2, b'\\x00\\xc05\\xad...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\x80\\x1b}\\x0e...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4, 17994575, 35919224]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 351886, 'value_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>8041</td>\n",
       "      <td>[(1, 90), (2, 184), (3, 183), (4, 110), (5, 18...</td>\n",
       "      <td>[(1, 11), (2, 11), (3, 11), (4, 11), (5, 11), ...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xe5_\\x91F\\x...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\x802\\xda\\xac...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 90, 'value_count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7501</td>\n",
       "      <td>[(1, 90), (2, 110), (3, 110), (4, 110), (5, 11...</td>\n",
       "      <td>[(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xb2,\\x91__\\...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xb2,\\x91__\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 90, 'value_count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7501</td>\n",
       "      <td>[(1, 90), (2, 110), (3, 110), (4, 110), (5, 11...</td>\n",
       "      <td>[(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@K^\\x89`_\\x04...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@K^\\x89`_\\x04...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 90, 'value_count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7565</td>\n",
       "      <td>[(1, 90), (2, 118), (3, 118), (4, 110), (5, 11...</td>\n",
       "      <td>[(1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\xc0\\x1a\\x8e\\...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xbac\\x14\\x8...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 90, 'value_count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>1</td>\n",
       "      <td>2964609</td>\n",
       "      <td>51732500</td>\n",
       "      <td>[(1, 352804), (2, 13713690), (3, 13898307), (4...</td>\n",
       "      <td>[(1, 2964609), (2, 2964609), (3, 2964609), (4,...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 140162), (5, 0), ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x01\\x00\\x00\\x00'), (2, b'\\x00 !\\x10\\xd...</td>\n",
       "      <td>[(1, b'\\x06\\x00\\x00\\x00'), (2, b'\\xc0(\\xae\\xb1...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4, 18218481, 36321783]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 352804, 'value_co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8028</td>\n",
       "      <td>[(1, 90), (2, 180), (3, 187), (4, 125), (5, 19...</td>\n",
       "      <td>[(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), ...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@s\\n\\xc6\\xd6\\...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xa5.\\x0b\\xd...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 90, 'value_count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7619</td>\n",
       "      <td>[(1, 90), (2, 127), (3, 127), (4, 118), (5, 12...</td>\n",
       "      <td>[(1, 3), (2, 3), (3, 3), (4, 3), (5, 3), (6, 3...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xdc\\xce\\xd7...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\x00\\x8c\\x83\\...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 90, 'value_count'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...</td>\n",
       "      <td>PARQUET</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7541</td>\n",
       "      <td>[(1, 90), (2, 110), (3, 110), (4, 110), (5, 11...</td>\n",
       "      <td>[(1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2...</td>\n",
       "      <td>[(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\xc0\\xccv% \\x...</td>\n",
       "      <td>[(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\xc0\\xccv% \\x...</td>\n",
       "      <td>None</td>\n",
       "      <td>[4]</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'VendorID': {'column_size': 90, 'value_count'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content                                          file_path file_format  \\\n",
       "0        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "1        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "2        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "3        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "4        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "5        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "6        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "7        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "8        0  s3://warehouse/demo_ns/nyc_taxis/data/tpep_pic...     PARQUET   \n",
       "\n",
       "   spec_id  record_count  file_size_in_bytes  \\\n",
       "0        2       3007511            52102669   \n",
       "1        2            11                8041   \n",
       "2        2             1                7501   \n",
       "3        2             1                7501   \n",
       "4        2             2                7565   \n",
       "5        1       2964609            51732500   \n",
       "6        1            10                8028   \n",
       "7        1             3                7619   \n",
       "8        1             2                7541   \n",
       "\n",
       "                                        column_sizes  \\\n",
       "0  [(1, 351886), (2, 13833395), (3, 14013827), (4...   \n",
       "1  [(1, 90), (2, 184), (3, 183), (4, 110), (5, 18...   \n",
       "2  [(1, 90), (2, 110), (3, 110), (4, 110), (5, 11...   \n",
       "3  [(1, 90), (2, 110), (3, 110), (4, 110), (5, 11...   \n",
       "4  [(1, 90), (2, 118), (3, 118), (4, 110), (5, 11...   \n",
       "5  [(1, 352804), (2, 13713690), (3, 13898307), (4...   \n",
       "6  [(1, 90), (2, 180), (3, 187), (4, 125), (5, 19...   \n",
       "7  [(1, 90), (2, 127), (3, 127), (4, 118), (5, 12...   \n",
       "8  [(1, 90), (2, 110), (3, 110), (4, 110), (5, 11...   \n",
       "\n",
       "                                        value_counts  \\\n",
       "0  [(1, 3007511), (2, 3007511), (3, 3007511), (4,...   \n",
       "1  [(1, 11), (2, 11), (3, 11), (4, 11), (5, 11), ...   \n",
       "2  [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1...   \n",
       "3  [(1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1...   \n",
       "4  [(1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2...   \n",
       "5  [(1, 2964609), (2, 2964609), (3, 2964609), (4,...   \n",
       "6  [(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), ...   \n",
       "7  [(1, 3), (2, 3), (3, 3), (4, 3), (5, 3), (6, 3...   \n",
       "8  [(1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2...   \n",
       "\n",
       "                                   null_value_counts nan_value_counts  \\\n",
       "0  [(1, 0), (2, 0), (3, 0), (4, 185610), (5, 0), ...               []   \n",
       "1  [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...               []   \n",
       "2  [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...               []   \n",
       "3  [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...               []   \n",
       "4  [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...               []   \n",
       "5  [(1, 0), (2, 0), (3, 0), (4, 140162), (5, 0), ...               []   \n",
       "6  [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...               []   \n",
       "7  [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...               []   \n",
       "8  [(1, 0), (2, 0), (3, 0), (4, 0), (5, 0), (6, 0...               []   \n",
       "\n",
       "                                        lower_bounds  \\\n",
       "0  [(1, b'\\x01\\x00\\x00\\x00'), (2, b'\\x00\\xc05\\xad...   \n",
       "1  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xe5_\\x91F\\x...   \n",
       "2  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xb2,\\x91__\\...   \n",
       "3  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@K^\\x89`_\\x04...   \n",
       "4  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\xc0\\x1a\\x8e\\...   \n",
       "5  [(1, b'\\x01\\x00\\x00\\x00'), (2, b'\\x00 !\\x10\\xd...   \n",
       "6  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@s\\n\\xc6\\xd6\\...   \n",
       "7  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xdc\\xce\\xd7...   \n",
       "8  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\xc0\\xccv% \\x...   \n",
       "\n",
       "                                        upper_bounds key_metadata  \\\n",
       "0  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\x80\\x1b}\\x0e...         None   \n",
       "1  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\x802\\xda\\xac...         None   \n",
       "2  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xb2,\\x91__\\...         None   \n",
       "3  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@K^\\x89`_\\x04...         None   \n",
       "4  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xbac\\x14\\x8...         None   \n",
       "5  [(1, b'\\x06\\x00\\x00\\x00'), (2, b'\\xc0(\\xae\\xb1...         None   \n",
       "6  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'@\\xa5.\\x0b\\xd...         None   \n",
       "7  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\x00\\x8c\\x83\\...         None   \n",
       "8  [(1, b'\\x02\\x00\\x00\\x00'), (2, b'\\xc0\\xccv% \\x...         None   \n",
       "\n",
       "             split_offsets equality_ids  sort_order_id  \\\n",
       "0  [4, 17994575, 35919224]         None            NaN   \n",
       "1                      [4]         None            NaN   \n",
       "2                      [4]         None            NaN   \n",
       "3                      [4]         None            NaN   \n",
       "4                      [4]         None            NaN   \n",
       "5  [4, 18218481, 36321783]         None            NaN   \n",
       "6                      [4]         None            NaN   \n",
       "7                      [4]         None            NaN   \n",
       "8                      [4]         None            NaN   \n",
       "\n",
       "                                    readable_metrics  \n",
       "0  {'VendorID': {'column_size': 351886, 'value_co...  \n",
       "1  {'VendorID': {'column_size': 90, 'value_count'...  \n",
       "2  {'VendorID': {'column_size': 90, 'value_count'...  \n",
       "3  {'VendorID': {'column_size': 90, 'value_count'...  \n",
       "4  {'VendorID': {'column_size': 90, 'value_count'...  \n",
       "5  {'VendorID': {'column_size': 352804, 'value_co...  \n",
       "6  {'VendorID': {'column_size': 90, 'value_count'...  \n",
       "7  {'VendorID': {'column_size': 90, 'value_count'...  \n",
       "8  {'VendorID': {'column_size': 90, 'value_count'...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_taxis_tbl.inspect.files().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshots\n",
    "\n",
    "If we want to look at snapshots of the table, we can query the `snapshots` metadata table.\n",
    "\n",
    "Every time when a data change operation happens, Iceberg will form a new snapshot. In this example, we did 2 append and therefore we will have 2 snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>committed_at</th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>operation</th>\n",
       "      <th>manifest_list</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-03 02:13:26.142</td>\n",
       "      <td>6445851743841051392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>append</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/metadata/snap...</td>\n",
       "      <td>[(added-files-size, 51755688), (added-data-fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-03 02:22:37.199</td>\n",
       "      <td>5248436113935406231</td>\n",
       "      <td>6.445852e+18</td>\n",
       "      <td>append</td>\n",
       "      <td>s3://warehouse/demo_ns/nyc_taxis/metadata/snap...</td>\n",
       "      <td>[(added-files-size, 52133277), (added-data-fil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             committed_at          snapshot_id     parent_id operation  \\\n",
       "0 2025-04-03 02:13:26.142  6445851743841051392           NaN    append   \n",
       "1 2025-04-03 02:22:37.199  5248436113935406231  6.445852e+18    append   \n",
       "\n",
       "                                       manifest_list  \\\n",
       "0  s3://warehouse/demo_ns/nyc_taxis/metadata/snap...   \n",
       "1  s3://warehouse/demo_ns/nyc_taxis/metadata/snap...   \n",
       "\n",
       "                                             summary  \n",
       "0  [(added-files-size, 51755688), (added-data-fil...  \n",
       "1  [(added-files-size, 52133277), (added-data-fil...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyc_taxis_tbl.inspect.snapshots().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more metadata tables available, you can find more information here: https://iceberg.apache.org/docs/nightly/spark-queries/#inspecting-tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperability with other engines: Spark\n",
    "\n",
    "Iceberg tables provides engine/platform interoperability. In above example, we use PyIceberg to perform all table operations, we will show that the tables created by PyIceberg can also be consumed by Spark\n",
    "\n",
    "First, let's set a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "  .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\")\n",
    "  .config(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.8.1,org.apache.iceberg:iceberg-aws-bundle:1.8.1\")\n",
    "  .config(\"spark.sql.catalog.demo.type\", \"rest\")\n",
    "  .config(\"spark.sql.catalog.demo\", \"org.apache.iceberg.spark.SparkCatalog\")  \n",
    "  .config(\"spark.sql.catalog.demo.uri\", \"http://rest:8181\")\n",
    "  .config(\"spark.sql.catalog.demo.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")       \n",
    "  .config(\"spark.sql.catalog.demo.warehouse\", \"s3://warehouse\")\n",
    "  .config(\"spark.sql.catalog.demo.s3.endpoint\", \"http://minio:9000\")\n",
    "  .config(\"spark.sql.catalog.demo.s3.region\", \"us-east-1\")\n",
    "  .config(\"spark.sql.catalog.demo.s3.path-style-access\", \"true\")\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query the nyc_taxis table we just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----------+\n",
      "| ID|tpep_pickup_datetime|fare_amount|\n",
      "+---+--------------------+-----------+\n",
      "|  2| 2024-02-01 00:04:45|       20.5|\n",
      "|  2| 2024-02-01 00:56:31|       31.0|\n",
      "|  2| 2024-02-01 00:07:50|       70.0|\n",
      "|  1| 2024-02-01 00:01:49|        9.3|\n",
      "|  1| 2024-02-01 00:37:35|       15.6|\n",
      "+---+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ID, tpep_pickup_datetime, fare_amount FROM demo.demo_ns.nyc_taxis LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query the metadata tables of nyc_taxis in spark. For examle, the `snapshots` metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|          parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|2025-04-03 02:13:...|6445851743841051392|               NULL|   append|s3://warehouse/de...|{added-files-size...|\n",
      "|2025-04-03 02:22:...|5248436113935406231|6445851743841051392|   append|s3://warehouse/de...|{added-files-size...|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM demo.demo_ns.nyc_taxis.snapshots\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
